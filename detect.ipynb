{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "names = [\"A\",\"B\",\"C\"]\n",
    "os.makedirs(\"./test\", exist_ok=True)\n",
    "\n",
    "for name in names:\n",
    "    in_dir = \"./face/\"+name+\"/*\"\n",
    "    in_jpg=glob.glob(in_dir)\n",
    "    img_file_name_list=os.listdir(\"./face/\"+name+\"/\")\n",
    "    random.shuffle(in_jpg)\n",
    "    os.makedirs('./test/' + name, exist_ok=True)\n",
    "    for t in range(len(in_jpg)//5):\n",
    "        shutil.move(str(in_jpg[t]), \"./test/\"+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "from scipy import ndimage\n",
    "\"\"\"\n",
    "faceディレクトリから画像を読み込んで回転、ぼかし、閾値処理をしてtrainディレクトリに保存する.\n",
    "\"\"\"\n",
    "names = [\"A\",\"B\",\"C\"]\n",
    "os.makedirs(\"./train\", exist_ok=True)\n",
    "for name in names:\n",
    "    in_dir = \"./face/\"+name+\"/*\"\n",
    "    out_dir = \"./train/\"+name\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    in_jpg=glob.glob(in_dir)\n",
    "    img_file_name_list=os.listdir(\"./face/\"+name+\"/\")\n",
    "    for i in range(len(in_jpg)):\n",
    "        img = cv2.imread(str(in_jpg[i]))\n",
    "        for ang in [-10,0,10]:\n",
    "            img_rot = ndimage.rotate(img,ang)\n",
    "            img_rot = cv2.resize(img_rot,(64,64))\n",
    "            fileName=os.path.join(out_dir,str(i)+\"_\"+str(ang)+\".jpg\")\n",
    "            cv2.imwrite(str(fileName),img_rot)\n",
    "            # 閾値\n",
    "            img_thr = cv2.threshold(img_rot, 100, 255, cv2.THRESH_TOZERO)[1]\n",
    "            fileName=os.path.join(out_dir,str(i)+\"_\"+str(ang)+\"thr.jpg\")\n",
    "            cv2.imwrite(str(fileName),img_thr)\n",
    "            # ぼかし\n",
    "            img_filter = cv2.GaussianBlur(img_rot, (5, 5), 0)\n",
    "            fileName=os.path.join(out_dir,str(i)+\"_\"+str(ang)+\"filter.jpg\")\n",
    "            cv2.imwrite(str(fileName),img_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "name = [\"A\",\"B\",\"C\"]\n",
    "\n",
    "# 教師データのラベル付け\n",
    "X_train = []\n",
    "Y_train = []\n",
    "for i in range(len(name)):\n",
    "    img_file_name_list=os.listdir(\"./train/\"+name[i])\n",
    "    print(len(img_file_name_list))\n",
    "    for j in range(0,len(img_file_name_list)-1):\n",
    "        n=os.path.join(\"./train/\"+name[i]+\"/\",img_file_name_list[j])\n",
    "        img = cv2.imread(n)\n",
    "        b,g,r = cv2.split(img)\n",
    "        img = cv2.merge([r,g,b])\n",
    "        X_train.append(img)\n",
    "        Y_train.append(i)\n",
    "\n",
    "# テストデータのラベル付け\n",
    "X_test = [] # 画像データ読み込み\n",
    "Y_test = [] # ラベル（名前）\n",
    "for i in range(len(name)):\n",
    "    img_file_name_list=os.listdir(\"./test/\"+name[i])\n",
    "    print(len(img_file_name_list))\n",
    "    for j in range(0,len(img_file_name_list)-1):\n",
    "        n=os.path.join(\"./test/\"+name[i]+\"/\",img_file_name_list[j])\n",
    "        img = cv2.imread(n)\n",
    "        b,g,r = cv2.split(img)\n",
    "        img = cv2.merge([r,g,b])\n",
    "        X_test.append(img)\n",
    "        # ラベルは整数値\n",
    "        Y_test.append(i)\n",
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)\n",
    "\n",
    "from keras.layers import Activation, Conv2D, Dense, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(Y_train)\n",
    "y_test = to_categorical(Y_test)\n",
    "\n",
    "# モデルの定義\n",
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(64, 64, 3), filters=32,kernel_size=(3, 3),\n",
    "                 strides=(1, 1), padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                 strides=(1, 1), padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
    "                 strides=(1, 1), padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# コンパイル\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 学習\n",
    "history = model.fit(X_train, y_train, batch_size=32,\n",
    "                    epochs=50, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# 汎化制度の評価・表示\n",
    "score = model.evaluate(X_test, y_test, batch_size=32, verbose=0)\n",
    "print('validation loss:{0[0]}\\nvalidation accuracy:{0[1]}'.format(score))\n",
    "\n",
    "#acc, val_accのプロット\n",
    "plt.plot(history.history[\"acc\"], label=\"acc\", ls=\"-\", marker=\"o\")\n",
    "plt.plot(history.history[\"val_acc\"], label=\"val_acc\", ls=\"-\", marker=\"x\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "#モデルを保存\n",
    "model.save(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import cv2, time\n",
    "from datetime import datetime\n",
    "import slackweb\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import  load_model\n",
    "import sys\n",
    "\n",
    "#proxy認証\n",
    "#os.environ[\"HTTP_PROXY\"] = \"proxy_adress\"\n",
    "#os.environ[\"HTTPS_PROXY\"] = \"proxy_adress\"\n",
    "\n",
    "# 正面の顔検出用\n",
    "cascPath = '-----Your_Path-----/lbpcascades/lbpcascade_frontalface.xml'\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "\n",
    "model = load_model('./my_model.h5')\n",
    "\n",
    "#Slackに通知を飛ばす\n",
    "#slack = slackweb.Slack(url=\"<https://hooks.slack.com/services/-----Your_adress-----\")\n",
    "\n",
    "def detect_who(img):\n",
    "    #予測\n",
    "    name=\"\"\n",
    "    print(model.predict(img))\n",
    "    nameNumLabel=np.argmax(model.predict(img))\n",
    "    if nameNumLabel== 0: \n",
    "        name=\"A\"\n",
    "    elif nameNumLabel==1:\n",
    "        name=\"B\"\n",
    "    elif nameNumLabel==2:\n",
    "        name=\"C\"\n",
    "    return name\n",
    "\n",
    "#MJPEGStream\n",
    "URL = \"-----raspberry_address------/?action=stream\"\n",
    "s_video = cv2.VideoCapture(URL)\n",
    "\n",
    "while True:\n",
    "  ret, img = s_video.read()\n",
    "\n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  gray = cv2.equalizeHist( gray )\n",
    "  faces = faceCascade.detectMultiScale(gray, 1.1, 3, 0, (10, 10))\n",
    "\n",
    "  for (x, y, w, h) in faces:\n",
    "      # 見つかった顔を矩形で囲む\n",
    "      cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "      time = datetime.now().strftime('%Y%m%d%H%M%S.%f')[:-3]\n",
    "      path = '.\\\\\\\\img\\\\\\\\' + time + '.jpg'\n",
    "      cut_face = img[y:y+h,x:x+w,:]\n",
    "      cut_face_resize = cv2.resize(cut_face,(64,64))\n",
    "      cv2.imwrite(path, cut_face_resize)\n",
    "      cut_face_resize=np.expand_dims(cut_face_resize,axis=0)\n",
    "      name = detect_who(cut_face_resize)\n",
    "      cv2.putText(cut_face_resize, name, (x, y+h+20), cv2.FONT_HERSHEY_DUPLEX, 1, (255,0,0), 2)\n",
    "      if name == \"A\":\n",
    "        # slack.notify(text=\" \"+name)\n",
    "    \n",
    "  cv2.imshow(\"Face-Detect-Video\",img)\n",
    "  key = cv2.waitKey(1) & 0xff\n",
    "  if key == ord('q'): break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
